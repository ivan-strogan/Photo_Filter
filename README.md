# Photo Filter AI App

An intelligent photo organization system that automatically clusters and organizes photos and videos based on temporal patterns, GPS location data, and visual content analysis.

## Features

- ğŸ“¸ **Smart Photo Detection**: Recognizes iPhone photo/video naming format (IMG_YYYYMMDD_HHMMSS.JPG/.MOV)
- ğŸ•’ **Temporal Clustering**: Groups media by time proximity with intelligent algorithms
- ğŸ“ **Location-Based Grouping**: Uses GPS metadata and reverse geocoding for location clustering
- ğŸ¤– **Computer Vision Analysis**: Analyzes photo content for objects, scenes, and activities
- ğŸ§  **Vector Database**: Uses CLIP embeddings for visual similarity matching with intelligent caching
- ğŸ¬ **Video Processing**: Intelligent frame extraction and vectorization for video files
- ğŸ¤– **Smart Learning**: Learns from existing organized photos to improve future naming
- âš¡ **Duplicate Detection**: Skips already-processed photos for lightning-fast subsequent runs
- âš™ï¸ **Configurable Parameters**: Customizable clustering thresholds and processing settings
- ğŸš€ **GPU Acceleration**: Supports CUDA and Apple MPS for faster processing
- ğŸ“Š **Comprehensive Logging**: Detailed progress tracking and session reports

## Project Structure

```
Photo_Filter/
â”œâ”€â”€ src/                     # Main source code
â”‚   â”œâ”€â”€ config.py           # Configuration settings
â”‚   â”œâ”€â”€ media_detector.py   # File detection and parsing
â”‚   â”œâ”€â”€ metadata_extractor.py # EXIF and GPS metadata extraction
â”‚   â”œâ”€â”€ content_analyzer.py # Computer vision content analysis
â”‚   â”œâ”€â”€ temporal_clustering.py # Time-based clustering algorithms
â”‚   â”œâ”€â”€ geocoding.py        # Location services and reverse geocoding
â”‚   â”œâ”€â”€ media_clustering.py # Comprehensive clustering engine
â”‚   â”œâ”€â”€ config_manager.py   # Configuration management system
â”‚   â”œâ”€â”€ photo_vectorizer.py # CLIP-based image & video vectorization
â”‚   â”œâ”€â”€ vector_database.py  # ChromaDB vector storage with smart caching
â”‚   â”œâ”€â”€ organized_photos_scanner.py # Learns from existing organized photos
â”‚   â””â”€â”€ ...
â”œâ”€â”€ tests/                  # Test suite
â”‚   â”œâ”€â”€ test_content_analyzer.py
â”‚   â”œâ”€â”€ test_location_verification.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ data/                   # Data files (config, cache)
â”œâ”€â”€ logs/                   # Log files
â”œâ”€â”€ main.py                # CLI interface
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ todo.txt              # Development roadmap
```

## Requirements

- **Python 3.11** (required for AI models)
- **CLIP and BLIP models** (required for content analysis)
- macOS, Linux, or Windows
- Optional: For face recognition features: CMake and dlib (see installation notes below)

## Installation

1. **Clone the repository**
   ```bash
   git clone <repository_url>
   cd Photo_Filter
   ```

2. **Create virtual environment with Python 3.11**
   ```bash
   python3.11 -m venv venv_py311
   source venv_py311/bin/activate  # On Windows: venv_py311\\Scripts\\activate
   ```

3. **Install core dependencies**
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

4. **Optional: Install face recognition dependencies**
   ```bash
   # macOS with Homebrew
   brew install cmake
   brew install dlib

   # Then install face-recognition (already in requirements.txt)
   pip install face-recognition
   ```

## Usage

### Prerequisites - Start Ollama LLM Server

**IMPORTANT**: Before running the photo organization pipeline, you must start the Ollama LLM server for intelligent event naming.

```bash
# In a separate terminal window, start Ollama server
ollama serve
```

Keep this terminal running while you use the Photo Filter app. The event naming system requires an active LLM connection and will fail if Ollama is not running.

**Install Ollama** (if not already installed):
```bash
# macOS/Linux
curl https://ollama.ai/install.sh | sh

# Or download from https://ollama.ai
```

**Download the required model**:
```bash
ollama pull llama3.1:8b
```

### CLI Commands

```bash
# Activate virtual environment
source venv_py311/bin/activate

# Scan existing organized photos
python main.py scan

# Process new unorganized photos (preview mode - doesn't move files)
python main.py process --dry-run

# Process and actually organize photos (moves/copies files to folders)
python main.py process --no-dry-run

# Analyze photo content
python main.py analyze-content --max-photos 10

# Show system status
python main.py status

# Configuration management
python main.py config show
python main.py config update --time-threshold 8.0
python main.py config reset

# Face recognition management
python main.py faces scan              # Build face database from organized photos
python main.py faces add "John Doe" photo1.jpg photo2.jpg  # Add person
python main.py faces list              # List known people
python main.py faces remove "John Doe" # Remove person
python main.py faces status            # Show face recognition status
```

### Configuration

The system uses a JSON configuration file with customizable parameters:

```json
{
  "clustering": {
    "time_threshold_hours": 6.0,
    "location_threshold_km": 1.0,
    "min_cluster_size": 3
  },
  "processing": {
    "max_photos_per_event": 50,
    "use_gpu": true,
    "enable_vectorization": true
  }
}
```

## File Organization

### Input Structure
```
Sample_Photos/
â”œâ”€â”€ iPhone Automatic/       # Unorganized photos from iPhone
â”‚   â”œâ”€â”€ IMG_20241024_143000.JPG
â”‚   â”œâ”€â”€ IMG_20241024_143015.MOV
â”‚   â””â”€â”€ ...
â””â”€â”€ Pictures/              # Existing organized photos
    â”œâ”€â”€ 2024/
    â”‚   â”œâ”€â”€ 2024_10_24 - Mexico Vacation/
    â”‚   â””â”€â”€ 2024_11_15 - Birthday Party/
    â””â”€â”€ ...
```

### Output Format
The system suggests organized folder names like:
- `2024_10_24 - Mexico Vacation`
- `2024_11_15 - Birthday Party - Quick Event`
- `2024_12_25 - Edmonton - All Day`

## Clustering Algorithm

The system uses a multi-stage clustering approach:

1. **Temporal Clustering**: Groups photos by time proximity using three algorithms:
   - `by_time`: Continuous time-based grouping
   - `by_day`: Day-boundary aware clustering
   - `activity_periods`: Natural activity pattern detection

2. **Location Enhancement**: Refines clusters using GPS coordinates and reverse geocoding

3. **Content Analysis**: Analyzes visual content for objects, scenes, and activities

4. **Confidence Scoring**: Calculates cluster quality based on multiple signals

## Testing

Run the test suite:

```bash
# Run individual tests
python tests/test_content_analyzer.py
python tests/test_location_verification.py

# Run all tests (with pytest)
pytest tests/
```

## Development Status

**Completed Features (18/24):**
- âœ… Media detection and parsing
- âœ… Metadata extraction (photos & videos)
- âœ… Temporal clustering algorithms
- âœ… Location-based clustering
- âœ… Computer vision content analysis
- âœ… Vector database integration
- âœ… Configuration management
- âœ… CLI interface
- âœ… Face detection and recognition

**In Progress:**
- âš ï¸ LLM integration for intelligent event naming

**Remaining Features:**
- ğŸ”„ Video content analysis
- ğŸ”„ Automated folder creation
- ğŸ”„ Media moving/copying system

## Dependencies

### Core Dependencies
- `click` - CLI interface
- `Pillow` - Image processing
- `exifread` - EXIF metadata extraction
- `geopy` - Geocoding services
- `numpy` - Numerical operations
- `python-dateutil` - Date parsing

### Required ML Dependencies
- `torch` - PyTorch for neural networks (REQUIRED)
- `transformers` - Hugging Face models for CLIP/BLIP (REQUIRED)
- `sentence-transformers` - Text embeddings
- `chromadb` - Vector database

Note: The application requires local AI models for content analysis. Install all dependencies from requirements.txt.

## Configuration

Key settings can be adjusted via the configuration system:

- **Time Threshold**: How close in time photos should be to cluster together
- **Location Threshold**: Geographic distance for location-based clustering
- **Cluster Size**: Minimum number of photos to form an event
- **GPU Usage**: Enable/disable GPU acceleration
- **Processing Limits**: Maximum photos per event for efficiency

## License

[Add your license here]

## Development Workflow

**MANDATORY**: All contributions must follow this GitHub workflow for proper tracking:

### 1. Create Issue First
```bash
gh issue create --title "type: description" --body "Requirements and acceptance criteria"
```

### 2. Create Feature Branch
```bash
git checkout -b feature/ISSUE#-description
# Example: git checkout -b feature/1-github-workflow-docs
```

### 3. Make Changes & Commit
```bash
git add .
git commit -m "type: description - addresses issue #ISSUE#"
```

### 4. Create Pull Request
```bash
git push -u origin feature/ISSUE#-description
gh pr create --title "type: description" --body "Fixes #ISSUE#"
```

Issues automatically close when PRs are merged, maintaining complete audit trails.

## Contributing

See [CLAUDE.md](./CLAUDE.md) for detailed development guidelines including:
- Architecture overview and data flow
- Testing procedures with pytest
- Configuration management
- Core commands and virtual environment setup# Photo_Filter
